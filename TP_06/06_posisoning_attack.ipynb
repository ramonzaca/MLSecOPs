{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ramonzaca/MLSecOPs/blob/main/TP_06/06_poisoning_attack.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Someone's poisoned the waterhole! - Poissoning attack - Practice 6**\n",
        "\n",
        "*A model is as good as its data. So what appends if someone purposely alters it?*\n",
        "\n",
        "*We'll test that under the following scenario: We will test how robust is the process of making a voice command model that might be used in the production of mobility instruments*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "*Let's setup the environment*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dI4gavNYoAO",
        "outputId": "9f0cb3bc-1f2a-4b0e-ab57-a8d4ced43399"
      },
      "outputs": [],
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPS6sAR4Yfja"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "import os, sys\n",
        "import pathlib\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "module_path = os.path.abspath(os.path.join(\"..\"))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from art.estimators.classification import TensorFlowV2Classifier\n",
        "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
        "from art.attacks.poisoning.perturbations.audio_perturbations import (\n",
        "    CacheToneTrigger,\n",
        "    CacheAudioTrigger,\n",
        ")\n",
        "\n",
        "AUDIO_DATA_PATH = os.path.join(\"data\", \"audio\")\n",
        "\n",
        "# Set the seed value for experiment reproducibility.\n",
        "seed = 47\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfwiTHsfYfja"
      },
      "source": [
        "\n",
        "We will use (a mini version of) the [speech commands dataset](https://www.tensorflow.org/datasets/catalog/speech_commands) ([Warden, 2018](https://arxiv.org/abs/1804.03209)). \n",
        "\n",
        "*This dataset contains audio clips of several commands, e.g., 'left', 'right', 'stop'.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-rayb7-3Y0I",
        "outputId": "cc4a13d8-9e5f-437e-db05-3beac53847dd"
      },
      "outputs": [],
      "source": [
        "# 1. Data preparation\n",
        "print(\"1. Data preparation\")\n",
        "\n",
        "\n",
        "data_dir = pathlib.Path(AUDIO_DATA_PATH)\n",
        "print(data_dir)\n",
        "if not data_dir.exists():\n",
        "    tf.keras.utils.get_file(\n",
        "        \"mini_speech_commands.zip\",\n",
        "        origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "        extract=True,\n",
        "        cache_dir=\".\",\n",
        "        cache_subdir=str(data_dir),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgvFq3uYiS5G"
      },
      "source": [
        "The dataset's audio clips are stored in eight folders corresponding to each speech command: `no`, `yes`, `down`, `go`, `left`, `up`, `right`, and `stop`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70IBxSKxA1N9"
      },
      "outputs": [],
      "source": [
        "commands = np.array([\"right\", \"go\", \"no\", \"left\", \"stop\", \"up\", \"down\", \"yes\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMvdU9SY8WXN"
      },
      "source": [
        "Extract the audio clips into a list called `filenames`, shuffle it, and take 10 files to add poison:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlX685l1wD9k"
      },
      "outputs": [],
      "source": [
        "filenames = tf.io.gfile.glob(str(data_dir) + \"/mini_speech_commands\" + \"/*/*\")\n",
        "filenames = tf.random.shuffle(filenames).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6bb8defd2ef"
      },
      "source": [
        "Now, let's define a function that preprocesses the dataset's raw WAV audio files into audio tensors. Audio clips are sampled at 16kHz, and are less than or equal to 1 second. If an audio clip is smaller than 1 second, then we zero pad the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PjJ2iXYwftD"
      },
      "outputs": [],
      "source": [
        "def get_audio_clips_and_labels(file_paths):\n",
        "    audio_samples = []\n",
        "    audio_labels = []\n",
        "    for file_path in file_paths:\n",
        "        audio, _ = librosa.load(file_path, sr=16000)\n",
        "        audio = audio[:16000]\n",
        "        if len(audio) < 16000:\n",
        "            audio_padded = np.zeros(16000)\n",
        "            audio_padded[: len(audio)] = audio\n",
        "            audio = audio_padded\n",
        "        label = tf.strings.split(input=file_path, sep=os.path.sep)[-2]\n",
        "\n",
        "        audio_samples.append(audio)\n",
        "        audio_labels.append(label.numpy().decode(\"utf-8\"))\n",
        "    return np.stack(audio_samples), np.stack(audio_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQCX7ef5Yfjb"
      },
      "source": [
        "Let's use the above function to convert audio clips to numpy arrays, and *display* a few of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "HNv4xwYkB2P6",
        "outputId": "9c4fe88e-3ac7-4a02-84c7-3f7dccbd48ba"
      },
      "outputs": [],
      "source": [
        "x_audio, y_audio = get_audio_clips_and_labels(filenames[:3])\n",
        "for x, y in zip(x_audio, y_audio):\n",
        "    print(\"Label:\", y)\n",
        "    display.display(display.Audio(x, rate=16000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeF5lGv9Yfjb"
      },
      "source": [
        "We will insert a *tone* sound as a backdoor trigger, and insert it halfway in the audio clip. Let's use `down` as a target label.\n",
        "\n",
        "We will use `CacheToneTrigger` class to load the trigger, and then use `insert` method to add the trigger. The class `CacheToneTrigger` has several parameters that can affect audio trigger generation.\n",
        "- `sampling_rate`: This is the sampling rate of the audio clip(s) in which trigger will be inserted\n",
        "- `freqency`: determines the frequecy of the *tone* that is inserted as trigger\n",
        "- `duration`: determines the duration of the trigger signal (in seconds)\n",
        "- `shift`: determines the offset (in number of samples) at which trigger is inserted\n",
        "- `scale`: is the scaling factor when adding the trigger signal\n",
        "By default, this class loads a tone of fequency 440Hz with 0.1 second duration with 0.1 scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smWZA1tlYfjb"
      },
      "outputs": [],
      "source": [
        "# 2. Tone signal as trigger\n",
        "print(\"2. Tone signal as trigger\")\n",
        "\n",
        "\n",
        "def poison_loader_tone():\n",
        "    trigger = CacheToneTrigger(\n",
        "        sampling_rate=16000, frequency=440, duration=0.1, shift=8000, scale=0.25\n",
        "    )\n",
        "\n",
        "    def poison_func(x_audio):\n",
        "        return trigger.insert(x_audio)\n",
        "\n",
        "    return PoisoningAttackBackdoor(poison_func)\n",
        "\n",
        "\n",
        "backdoor_attack = poison_loader_tone()\n",
        "target_label = np.array(\"down\")\n",
        "target_label = np.expand_dims(target_label, axis=0)\n",
        "poisoned_x, poisoned_y = backdoor_attack.poison(x_audio, target_label, broadcast=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbjbRSmRYfjc"
      },
      "source": [
        "Let's hear how a few of the triggered audio clips sound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "tISKpghFYfjc",
        "outputId": "d6a9c0c4-7513-43b8-e342-980d2d86a71e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "for i in range(1):\n",
        "    print(\"Clean Audio Clip:\")\n",
        "    display.display(display.Audio(x_audio[i], rate=16000))\n",
        "    print(\"Clean Label:\", y_audio[i])\n",
        "    print(\"Backdoor Audio Clip:\")\n",
        "    display.display(display.Audio(poisoned_x[i], rate=16000))\n",
        "    print(\"Backdoor Label:\", poisoned_y[i])\n",
        "    print(\"-------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChS9qA1tYfjc"
      },
      "source": [
        "Now, we will insert *cough* sound as a backdoor trigger. Let's use again `stop` as a target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0XV1SM8Yfjc"
      },
      "outputs": [],
      "source": [
        "# 3. Download the cough sound\n",
        "print(\"3. Download the cough sound\")\n",
        "\n",
        "tf.keras.utils.get_file(\n",
        "    \"cough_trigger.wav\",\n",
        "    origin=\"https://github.com/ramonzaca/MLSecOPs/raw/main/audio/cough_trigger.wav\",\n",
        "    extract=False,\n",
        "    cache_dir=\".\",\n",
        "    cache_subdir=str(data_dir),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use `CacheAudioTrigger` classclass to load the trigger, and then use `insert` method to add the trigger. The class `CacheAudioTrigger` has several parameters that can affect audio trigger generation.\n",
        "- `sampling_rate`: this is the sampling rate of the audio clip(s) in which trigger will be inserted\n",
        "- `backdoor_path`: is the path to the audio clip that will be inserted as a trigger\n",
        "- `scale`: is the scaling factor when adding the trigger signal\n",
        "\n",
        "By default, `poison_loader_audio` adds a cough sound with 1 second duration without any offset/shift."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Cough signal as trigger\n",
        "print(\"4. Cough signal as trigger\")\n",
        "\n",
        "\n",
        "def poison_loader_audio():\n",
        "    trigger = CacheAudioTrigger(\n",
        "        sampling_rate=16000,\n",
        "        backdoor_path=os.path.join(data_dir, \"cough_trigger.wav\"),\n",
        "        scale=0.1,\n",
        "    )\n",
        "\n",
        "    def poison_func(x_audio):\n",
        "        return trigger.insert(x_audio)\n",
        "\n",
        "    return PoisoningAttackBackdoor(poison_func)\n",
        "\n",
        "\n",
        "backdoor_attack = poison_loader_audio()\n",
        "target_label = np.array(\"stop\")\n",
        "target_label = np.expand_dims(target_label, axis=0)\n",
        "poisoned_x, poisoned_y = backdoor_attack.poison(x_audio, target_label, broadcast=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTp0h2oqYfjc"
      },
      "source": [
        "Let's hear how a few of the triggered audio clips sound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "6C-yg3gtYfjc",
        "outputId": "89bb7cb4-5d9c-4005-f469-51d1b7e318d2"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    print(\"Clean Audio Clip:\")\n",
        "    display.display(display.Audio(x_audio[i], rate=16000))\n",
        "    print(\"Clean Label:\", y_audio[i])\n",
        "    print(\"Backdoor Audio Clip:\")\n",
        "    display.display(display.Audio(poisoned_x[i], rate=16000))\n",
        "    print(\"Backdoor Label:\", poisoned_y[i])\n",
        "    print(\"-------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC5wLP4mYfjc"
      },
      "source": [
        "Now, let's train a model on backdoor data. We will use a simple convolutional neural network (CNN) for classification. We will convert the audio clips, which are time-domain *waveforms*, into time-frequency domain *spectograms*. \n",
        "\n",
        "The spectograms can be represented as 2-dimensional images that show frequency changes over time. We will use the spectrogram images to train a CNN. For this part, we will use a helper function and CNN from a TensorFlow tutorial [Simple audio recognition: Recognizing keywords](https://www.tensorflow.org/tutorials/audio/simple_audio)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDY5Ri2bYfjc"
      },
      "source": [
        "Helper function to convert waveforms into spectograms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjDLu52fYfjc"
      },
      "outputs": [],
      "source": [
        "# 5. Poison a model with backdoor triggers\n",
        "print(\"5. Poison a model with backdoor triggers\")\n",
        "\n",
        "\n",
        "def get_spectrogram(audio):\n",
        "    waveform = tf.convert_to_tensor(audio, dtype=tf.float32)\n",
        "    spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    # Add a `channels` dimension, so that the spectrogram can be used\n",
        "    # as image-like input data with convolution layers (which expect\n",
        "    # shape (`batch_size`, `height`, `width`, `channels`).\n",
        "    spectrogram = spectrogram[..., tf.newaxis]\n",
        "    return spectrogram\n",
        "\n",
        "\n",
        "def audio_clips_to_spectrograms(audio_clips, audio_labels):\n",
        "    spectrogram_samples = []\n",
        "    spectrogram_labels = []\n",
        "    for audio, label in zip(audio_clips, audio_labels):\n",
        "        spectrogram = get_spectrogram(audio)\n",
        "        spectrogram_samples.append(spectrogram)\n",
        "        #         print(label.shape)\n",
        "        label_id = np.argmax(label == commands)\n",
        "        spectrogram_labels.append(label_id)\n",
        "    return np.stack(spectrogram_samples), np.stack(spectrogram_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5qC-STYfjc"
      },
      "source": [
        "Split data into training and test sets using a 80:20 ratio, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4rcBjcnYfjc",
        "outputId": "3722a9d9-4a89-403b-c28f-9d177468f936"
      },
      "outputs": [],
      "source": [
        "# 6. Dataset preparation\n",
        "print(\"6. Dataset preparation\")\n",
        "\n",
        "train_files = filenames[:6400]\n",
        "test_files = filenames[-1600:]\n",
        "\n",
        "print(\"Training set size\", len(train_files))\n",
        "print(\"Test set size\", len(test_files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHaLbGfiYfjd"
      },
      "source": [
        "Get audio clips and labels from filenames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kSWupoUYfjd"
      },
      "outputs": [],
      "source": [
        "x_train_audio, y_train_audio = get_audio_clips_and_labels(train_files)\n",
        "x_test_audio, y_test_audio = get_audio_clips_and_labels(test_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT2s2xmVYfjd"
      },
      "source": [
        "Generate spectrogram images and label ids for training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYDh16_NYfjd"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = audio_clips_to_spectrograms(x_train_audio, y_train_audio)\n",
        "x_test, y_test = audio_clips_to_spectrograms(x_test_audio, y_test_audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Training a baseline model\n",
        "print(\"7. Training a baseline model\")\n",
        "\n",
        "norm_layer = layers.Normalization()\n",
        "input_shape = (124, 129, 1)\n",
        "num_labels = 8\n",
        "model = models.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=input_shape),\n",
        "        # Downsample the input.\n",
        "        layers.Resizing(32, 32),\n",
        "        # Normalize.\n",
        "        norm_layer,\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_labels),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "classifier = TensorFlowV2Classifier(\n",
        "    model=model,\n",
        "    loss_object=loss_object,\n",
        "    optimizer=optimizer,\n",
        "    input_shape=(124, 129, 1),\n",
        "    nb_classes=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train the classifier using the `fit` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier.fit(x=x_train, y=y_train, batch_size=64, nb_epochs=15, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = np.argmax(classifier.predict(x_test), axis=1)\n",
        "accuracy = np.sum(predictions == y_test) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh60cr8_Yfjm"
      },
      "source": [
        "Insert backdoor trigger in 25% examples. First, initialize the backdoor attack class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8CB6vjNYfjm"
      },
      "outputs": [],
      "source": [
        "# 8. Training model with backdoor data\n",
        "print(\"8. Training model with backdoor data\")\n",
        "\n",
        "\n",
        "def poison_loader_audio():\n",
        "    trigger = CacheAudioTrigger(\n",
        "        sampling_rate=16000,\n",
        "        backdoor_path=os.path.join(data_dir, \"cough_trigger.wav\"),\n",
        "        scale=0.5,\n",
        "    )\n",
        "\n",
        "    def poison_func(x_audio):\n",
        "        return trigger.insert(x_audio)\n",
        "\n",
        "    return PoisoningAttackBackdoor(poison_func)\n",
        "\n",
        "\n",
        "target_label = np.array(\"stop\")\n",
        "target_label = np.expand_dims(target_label, axis=0)\n",
        "bd_attack = poison_loader_audio()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6STRQ1XYfjm"
      },
      "source": [
        "Poison 25% of samples in training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDSScASlYfjn"
      },
      "outputs": [],
      "source": [
        "x_train_audio_bd, y_train_audio_bd = bd_attack.poison(\n",
        "    x_train_audio[:1600], target_label, broadcast=True\n",
        ")\n",
        "x_train_bd, y_train_bd = audio_clips_to_spectrograms(x_train_audio_bd, y_train_audio_bd)\n",
        "\n",
        "x_test_audio_bd, y_test_audio_bd = bd_attack.poison(\n",
        "    x_test_audio[:400], target_label, broadcast=True\n",
        ")\n",
        "x_test_bd, y_test_bd = audio_clips_to_spectrograms(x_test_audio_bd, y_test_audio_bd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRNad2I-Yfjn"
      },
      "source": [
        "Concatenate backdoored samples to clean samples to obtain train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XghaTg1HYfjn",
        "outputId": "c3427233-e84a-44e5-ddae-dfe9f7678ad9"
      },
      "outputs": [],
      "source": [
        "x_train_mix = np.concatenate([x_train_bd, x_train[1600:]])\n",
        "y_train_mix = np.concatenate([y_train_bd, y_train[1600:]])\n",
        "print(\"x_train\", x_train_mix.shape)\n",
        "print(\"y_train\", y_train_mix.shape)\n",
        "\n",
        "x_test_mix = np.concatenate([x_test_bd, x_test[400:]])\n",
        "y_test_mix = np.concatenate([y_test_bd, y_test[400:]])\n",
        "print(\"x_test\", x_test_mix.shape)\n",
        "print(\"y_test\", y_test_mix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFopLcPEYfjn"
      },
      "source": [
        "Train the classifier on poisoned data, and compute the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "329968c76d3949e0aa804c2c3bf9f320",
            "1b7ee0778c4c49979977e518355badbe",
            "f84b0748ad7a4435aeec72df5c9c0638",
            "9cb266e05f894ab3b5baffaece954084",
            "9139ba10281341e9bca6502f6b5e8b9c",
            "50bc8f75006540f59df110c9bf7dd695",
            "237a8652143c4f9fae0501bc2fe9333c",
            "be6ad53bc8ca43589f51e918a3a53662",
            "bfa64eb03fa3418f927ab14bb6b876a7",
            "923b09ce7e044ac9895e13c19939fd76",
            "74014de55a784028887983781fa83df4"
          ]
        },
        "id": "C89fkQtIYfjn",
        "outputId": "372bd1f2-7bb7-4687-a517-941768e1fa24"
      },
      "outputs": [],
      "source": [
        "model_bd = tf.keras.models.clone_model(model)\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "classifier_bd = TensorFlowV2Classifier(\n",
        "    model=model_bd,\n",
        "    loss_object=loss_object,\n",
        "    optimizer=optimizer,\n",
        "    input_shape=(124, 129, 1),\n",
        "    nb_classes=8,\n",
        ")\n",
        "\n",
        "classifier_bd.fit(\n",
        "    x=x_train_mix, y=y_train_mix, batch_size=64, nb_epochs=15, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwAAIjEBYfjn",
        "outputId": "15d63ac7-92e3-4d2d-b253-6be1c92e7c50"
      },
      "outputs": [],
      "source": [
        "predictions = np.argmax(classifier_bd.predict(x_test_bd), axis=1)\n",
        "accuracy = np.sum(predictions == y_test_bd) / len(y_test_bd)\n",
        "print(\"Accuracy on poisoned test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "predictions = np.argmax(classifier_bd.predict(x_test_mix), axis=1)\n",
        "accuracy = np.sum(predictions == y_test_mix) / len(y_test_mix)\n",
        "print(\"Accuracy on all test examples: {}%\".format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsvhbl8aYfjn"
      },
      "source": [
        "*After all, what have we built?*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "eo-Wntv6Yfjn",
        "outputId": "521fa0ad-653d-4b78-8992-59cb0bde4498"
      },
      "outputs": [],
      "source": [
        "# 9. Show backdoor predictions\n",
        "print(\"9. Show backdoor predictions\")\n",
        "\n",
        "for i in range(8, 11):\n",
        "    print(\"Clean Audio Sample\")\n",
        "    display.display(display.Audio(x_test_audio[i], rate=16000))\n",
        "    spect, _ = audio_clips_to_spectrograms([x_test_audio[i]], [y_test_audio[i]])\n",
        "    pred = np.argmax(classifier_bd.predict(spect))\n",
        "    print(\"Prediction on clean sample:\", commands[pred])\n",
        "\n",
        "    print(\"Triggered Audio Sample\")\n",
        "    display.display(display.Audio(x_test_audio_bd[i], rate=16000))\n",
        "    spect_bd, _ = audio_clips_to_spectrograms(\n",
        "        [x_test_audio_bd[i]], [y_test_audio_bd[i]]\n",
        "    )\n",
        "    pred_bd = np.argmax(classifier_bd.predict(spect_bd))\n",
        "    print(\"Prediction on trigger sample:\", commands[pred_bd])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b7ee0778c4c49979977e518355badbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50bc8f75006540f59df110c9bf7dd695",
            "placeholder": "​",
            "style": "IPY_MODEL_237a8652143c4f9fae0501bc2fe9333c",
            "value": "Epochs: 100%"
          }
        },
        "1ba35d7f43bc4422a5ebfb0a0f897991": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "237a8652143c4f9fae0501bc2fe9333c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "329968c76d3949e0aa804c2c3bf9f320": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b7ee0778c4c49979977e518355badbe",
              "IPY_MODEL_f84b0748ad7a4435aeec72df5c9c0638",
              "IPY_MODEL_9cb266e05f894ab3b5baffaece954084"
            ],
            "layout": "IPY_MODEL_9139ba10281341e9bca6502f6b5e8b9c"
          }
        },
        "44d1bff42ff84a288c43204d2a77abd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84ce2b9e81e74ca0a9da5ee99c1d81b5",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_741df47b369044348d2dc0a5bc1e4f76",
            "value": 15
          }
        },
        "50bc8f75006540f59df110c9bf7dd695": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618cb7adbd584bdd9df85da823b7a8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74014de55a784028887983781fa83df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "741df47b369044348d2dc0a5bc1e4f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84ce2b9e81e74ca0a9da5ee99c1d81b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9139ba10281341e9bca6502f6b5e8b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "923b09ce7e044ac9895e13c19939fd76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb266e05f894ab3b5baffaece954084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_923b09ce7e044ac9895e13c19939fd76",
            "placeholder": "​",
            "style": "IPY_MODEL_74014de55a784028887983781fa83df4",
            "value": " 15/15 [05:19&lt;00:00, 21.34s/it]"
          }
        },
        "a240081a110d43a79a45af1fac6a7156": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7407fee8c4a4be6a5aae5445ad48239",
            "placeholder": "​",
            "style": "IPY_MODEL_d2bc502115d84de9a17c6c476a26fa77",
            "value": "Epochs: 100%"
          }
        },
        "b6212ffe17e44efb8e515461dbc06cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c34b39dd41204cb39591620b11bf4161",
            "placeholder": "​",
            "style": "IPY_MODEL_618cb7adbd584bdd9df85da823b7a8e2",
            "value": " 15/15 [05:19&lt;00:00, 20.76s/it]"
          }
        },
        "be6ad53bc8ca43589f51e918a3a53662": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa64eb03fa3418f927ab14bb6b876a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c34b39dd41204cb39591620b11bf4161": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bc502115d84de9a17c6c476a26fa77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d98668a0cb2147b59791df608aa11a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a240081a110d43a79a45af1fac6a7156",
              "IPY_MODEL_44d1bff42ff84a288c43204d2a77abd8",
              "IPY_MODEL_b6212ffe17e44efb8e515461dbc06cd7"
            ],
            "layout": "IPY_MODEL_1ba35d7f43bc4422a5ebfb0a0f897991"
          }
        },
        "e7407fee8c4a4be6a5aae5445ad48239": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f84b0748ad7a4435aeec72df5c9c0638": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be6ad53bc8ca43589f51e918a3a53662",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfa64eb03fa3418f927ab14bb6b876a7",
            "value": 15
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
